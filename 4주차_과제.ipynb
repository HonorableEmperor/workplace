{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제 최종본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ": MCP(Mcculloch-pitts)뉴런은 여러 개의 입력 신호가 가지돌기에 도착하면 신경세포 내에서 이들을 하나의 신호로 통합하고, 통합된 신호 값이 어떤 임계값을 초과하면 하나의 단일 신호가 생성되며, 이 신호가 축삭돌기(Axon)를 통해 다른 신경세포로 전달하는 단순화된 원리로 동작하는 뇌 세포를 뜻한다. MCP 뉴런은 이후 Frank Rosenblatt의 퍼셉트론 학습 규칙에 그 개념이 사용된다.   \n",
        "Reference:   \n",
        "https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220948258166&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
        "\n",
        "### 퍼셉트론\n",
        ": 퍼셉트론(perceptron)은 MCP 뉴런 모델 개념을 기초로 한 알고리즘으로, 하나의 MCP 뉴런이 출력신호 발생 여부를 결정하는 것을 목적으로 MCP 뉴런으로 들어오는 각 입력 값에 곱해지는 가중치(Weight) 값을 자동 학습하는 알고리즘을 뜻한다.   \n",
        " 퍼셉트론 내 주요 개념인 가중치에 대하여 간단히 추가적으로 설명하자면, 먼저 각 입력신호에 있어 고유한 가중치가 부가된다. 이후 부여된 가중치는 입력신호와의 계산을 하고, 신호의 총합이 정해진 임계값(θ; theta, 세타)를 넘었을 때 1을 출력하도록 하며, 넘지 못하면 0 또는 -1을 출력하도록 한다. 추가로, weight가 클수록 해당 신호의 중요성 역시 커진다.   \n",
        "  정리해서, 해당 알고리즘이 하는 일은 이 weight의 값을 정하는 작업이라 할 수 있으며, 퍼셉트론의 출력 값은 1 또는 0(or -1)이기에 선형 분류 모형이라고도 볼 수 있다.   \n",
        "  Reference:   \n",
        "  https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220948258166&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
        "https://sacko.tistory.com/10\n",
        "\n",
        "\n",
        "### 역전파\n",
        ": 역전파(backpropagation)는 역방향으로 오차를 전파시키면서 각층의 가중치를 업데이트하고 최적의 학습결과를 찾아가는 방법으로, 풀어서 설명하면 계산 결과와 정답의 오차를 구해 이 오차에 관여하는 값들의 가중치를 수정하여 오차가 작아지는 방향으로 일정 횟수를 반복해 수정하는 방법을 뜻한다. 또한, 역전파 알고리즘은 사슬 규칙을 이용하는 기울기 기반 최적화 알고리즘에 따라 인공신경망(ANN)을 효율적으로 훈련하는데 사용되는 방법이다.   \n",
        "이러한 방법은 순전파를 통해 출력층에서 계산된 오차의 각 가중치에 따른 미세변화를 입력층 방향으로 역전파시키면서 가중치를 업데이트하며, 또 다시 입력값을 이용해 순전파시켜 출력층에서 새로운 오차를 계산하고, 이 오차를 또다시 역전파시켜 가중치를 업데이트 하는 것을 반복하는 과정 속에서 활용된다.   \n",
        "Reference:   \n",
        "\n",
        "https://m.blog.naver.com/samsjang/221033626685\n",
        "https://sacko.tistory.com/19\n",
        "http://wiki.hash.kr/index.php/%EC%97%AD%EC%A0%84%ED%8C%8C\n",
        "\n",
        "\n",
        "### 강화학습\n",
        ": 강화학습(Reinforcement learning)은 기계학습의 한 영역으로, 행동심리학에서 영감을 받아 어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법이다. 이는 통계학, 유전 알고리즘 등 다양한 분야에서 연구되고 있다.   \n",
        "또한, 강화 학습은 입출력 쌍으로 이루어진 훈련 집합이 제시되지 않으며, 잘못된 행동에 대해서도 명시적으로 정정이 일어나지 않는다는 점에서 일반적인 지도 학습과는 다르다. 대신, 강화학습의 초점은 학습 과정에서의 성능이며, 이는 탐색(exploration)과 이용(exploitation)의 균형을 맞춤으로써 제고된다. 추가적으로, 탐색과 이용의 균형 문제 강화 학습에서 가장 많이 연구된 문제로, 다중 슬롯 머신 문제와 유한한 마르코프 결정 과정 등에서 연구되었다.   \n",
        "Reference:   \n",
        "https://ko.wikipedia.org/wiki/%EA%B0%95%ED%99%94_%ED%95%99%EC%8A%B5#:~:text=%EA%B0%95%ED%99%94%20%ED%95%99%EC%8A%B5(Reinforcement%20learning)%EC%9D%80,%EB%A5%BC%20%EC%84%A0%ED%83%9D%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95%EC%9D%B4%EB%8B%A4.\n",
        "\n",
        "\n",
        "### 과적합\n",
        ": 과적합(overfitting)은 기계 학습에서 학습 데이터를 과하게 학습하는 것을 뜻한다. 일반적으로 학습 데이터는 실제 데이터의 부분 집합이므로 학습 데이터에 대해서는 오차가 감소하지만, 실제 데이터에 대해서는 오차가 증가하게 된다.   \n",
        " 추가적으로, 이러한 과적합 문제를 해결하기 위한 방법들은 계속해서 연구되어왔는데, 그 중 하나로 support vector machine을 들 수가 있다. 이는 기존의 인공신경망(artificial neural network, ANN)이나 에너지 모델과는 다르게 데이터를 분류하기 위한 decision surface를 찾는 것과 동시에 각 데이터의 집합과 decision surface간의 거리(margin)를 최대화하는 방식으로 학습을 진행하는 방법이다.   \n",
        " Reference:   \n",
        " https://ko.wikipedia.org/wiki/%EA%B3%BC%EC%A0%81%ED%95%A9\n",
        "https://untitledtblog.tistory.com/68\n",
        "\n",
        "\n",
        "### 차원의 저주\n",
        ":  차원의 저주(curse of dimensionality)란, 데이터 학습을 위해 차원이 증가하는 과정 속에서 학습 데이터 수가 차원의 수보다 적어져 성능이 저하되는 현상을 뜻한다. 변수가 많아지면 데이터에 대한 정보도 많아지니 얼핏 보기에는 이러한 변수의 증가는 긍정적인 효과만을 줄 듯 하지만, 변수의 수가 많아지면 차원이 커지게 되므로 분석을 위한 최소한의 필요 데이터 건수도 많아지게 된다.   \n",
        "참고로, 충분히 공간을 표현할 만큼 큰 데이터 수집 없이, 적은 데이터로만 이 공간을 표현하는 경우 과적합이 발생할 수 있다.      \n",
        "Reference:   \n",
        "\n",
        "https://kkokkilkon.tistory.com/127\n",
        "https://datapedia.tistory.com/15\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LWmi3-SzDd3",
        "colab_type": "code",
        "outputId": "22ee213d-0a4a-4770-9238-169488dcbc58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1],0,1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x) :\n",
        "  return 1/(1 + math.exp(-x))\n",
        "\n",
        "output = sigmoid( x * w )\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x*w)\n",
        "  error = y - output\n",
        "  w = w + x* 0.1 * error #경사하강법; 가중치 + 입력*학습률(가중치 조정을 위한 하이퍼 파라미터)*에러(출력값 - 시그모이드(입력*가중치))\n",
        "#입력값에 0이 들어오면 이후 가중치에 더해지는 값이 없어져버림. 이때 편향의 개념이 필요함.\n",
        "  \n",
        "  if i % 100 == 99:\n",
        "    print(\"학습 횟수:\",i, \"Error:\",error, \"예측 결과:\", output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수: 99 Error: -0.10010598284299604 예측 결과: 0.10010598284299604\n",
            "학습 횟수: 199 Error: -0.05178399422833116 예측 결과: 0.05178399422833116\n",
            "학습 횟수: 299 Error: -0.034590451977903586 예측 결과: 0.034590451977903586\n",
            "학습 횟수: 399 Error: -0.02588962752851373 예측 결과: 0.02588962752851373\n",
            "학습 횟수: 499 Error: -0.020658699939863617 예측 결과: 0.020658699939863617\n",
            "학습 횟수: 599 Error: -0.017174253993457355 예측 결과: 0.017174253993457355\n",
            "학습 횟수: 699 Error: -0.014689506449480992 예측 결과: 0.014689506449480992\n",
            "학습 횟수: 799 Error: -0.012829497265431342 예측 결과: 0.012829497265431342\n",
            "학습 횟수: 899 Error: -0.011385568271837804 예측 결과: 0.011385568271837804\n",
            "학습 횟수: 999 Error: -0.010232493309882492 예측 결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    }
  ]
}